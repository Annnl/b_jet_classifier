{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13098de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy version:  1.22.3\n",
      "pandas version:  1.4.4\n",
      "uproot version:  4.3.7\n",
      "awkward version:  1.10.1\n",
      "Tensorflow version:  2.9.1\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# source :\n",
    "# https://github.com/wikibook/dl-vision/blob/master/Chapter07/ch7_nb5_train_a_simple_domain_adversarial_network_(dann).ipynb\n",
    "# DANN model setup by Egor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "#import ROOT\n",
    "import os\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import uproot as ur\n",
    "import awkward as ak\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Model\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import yaml\n",
    "import argparse\n",
    "import collections\n",
    "pd.set_option('display.max_columns', None)\n",
    "np.random.seed(31415)\n",
    "#print('ROOT version: ', ROOT.__version__)\n",
    "print('numpy version: ', np.__version__)\n",
    "print('pandas version: ', pd.__version__)\n",
    "print('uproot version: ', ur.__version__)\n",
    "print('awkward version: ', ak.__version__)\n",
    "print('Tensorflow version: ', tf.__version__)\n",
    "print(tf.config.list_physical_devices('GPU'))\n",
    "\n",
    "\n",
    "batch_size = 50 # put to config file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d7ac277",
   "metadata": {
    "code_folding": [
     69
    ]
   },
   "outputs": [],
   "source": [
    "###\n",
    "# Get arguments from the command line\n",
    "#parser = argparse.ArgumentParser()\n",
    "#parser.add_argument('-c', '--config_file', type = str, help = 'config file in .yml format')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "\n",
    "###\n",
    "# Create output directory for plots\n",
    "#os.system('mkdir figures/' + datetime.now().strftime('%d_%m_%Y_%H%M'))\n",
    "#plot_dir = 'figures/' + datetime.now().strftime('%d_%m_%Y_%H%M') + \"/\"\n",
    "\n",
    "\n",
    "###\n",
    "# Open config file\n",
    "#with open(args.config_file, 'r') as file:\n",
    "#    config = yaml.safe_load(file)\n",
    "feature_list = ['bjet_pt', 'dR_lep_close', 'dR_lep_far', 'mass_lep_close',\n",
    "       'mass_lep_far', 'dR_bjet_close', 'dR_bjet_far', 'dR_lep_el',\n",
    "       'dR_lep_mu', 'mass_lep_el', 'mass_lep_mu', 'dR_lep_1pt', 'dR_lep_2pt',\n",
    "       'mass_lep_1pt', 'mass_lep_2pt', 'mass_bjet_large', 'mass_bjet_small']\n",
    "\n",
    "config={'in_nominal_file': \n",
    "        {'name': '3j3b.root', 'tree': 'ttbar', 'features': feature_list, \n",
    "         'target': 'jet_GBHInit_topHadronOriginFlag', 'sig_val': [-99, 0, 1], 'bkg_val': [4], \n",
    "         'weights': 'total_event_weight'}, 'in_nominal_for_domain_file': \n",
    "        {'name': '3j3b.root', 'tree': 'ttbar', 'features': feature_list, \n",
    "         'target': 'jet_GBHInit_topHadronOriginFlag', 'sig_val': [-99, 0, 1, 4], \n",
    "         'bkg_val': [], 'weights': 'total_event_weight'}, 'in_domain1_file':\n",
    "        {'name': '3j3b_sherpa.root', 'tree': 'ttbar', 'features': feature_list, \n",
    "         'target': 'jet_GBHInit_topHadronOriginFlag', 'sig_val': [], 'bkg_val': [-99, 0, 1, 4], \n",
    "         'weights': 'total_event_weight'}, 'in_domain2_file': \n",
    "        {'name': '3j3b_sherpa_set3.root', 'tree': 'ttbar', 'features': feature_list, \n",
    "         'target': 'jet_GBHInit_topHadronOriginFlag', 'sig_val': [], 'bkg_val': [-99, 0, 1, 4],\n",
    "         'weights': 'total_event_weight'}, 'train_size': 0.75, 'validation_size': 0.1, \n",
    "        'model': {'new_or_load': 'new', 'name': 'my_model', 'hidden_layers': [50, 40, 30, 20, 10, 5],\n",
    "                  'act_func': ['relu', 'relu', 'relu', 'relu', 'relu', 'relu'], \n",
    "                  'epochs': 25, 'loss': 'binary_crossentropy', 'metrics': \n",
    "    #['AUC', 'accuracy', 'FalseNegatives', 'FalsePositives', 'Precision', 'Recall', 'TrueNegatives', 'TruePositives']}}\n",
    "     ['AUC', 'accuracy']}}\n",
    "\n",
    "\n",
    "###\n",
    "# Define a few learning rate functions\n",
    "initial_learning_rate = 0.001\n",
    "#decay = initial_learning_rate / config['model']['epochs']\n",
    "\n",
    "def lr_time_based_decay(epoch, lr):\n",
    "    learning_rate = lr * 1 / (1 + decay * epoch)\n",
    "    tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate\n",
    "\n",
    "def lr_step_decay(epoch, lr):\n",
    "    drop_rate = 0.5\n",
    "    epochs_drop = 10.0\n",
    "    learning_rate = initial_learning_rate * math.pow(drop_rate, math.floor(epoch/epochs_drop))\n",
    "    tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate\n",
    "\n",
    "def lr_exp_decay(epoch, lr):\n",
    "    k = 0.1\n",
    "    learning_rate = initial_learning_rate * math.exp(-k*epoch)\n",
    "    tf.summary.scalar('learning rate', data=learning_rate, step=epoch)\n",
    "    return learning_rate\n",
    "\n",
    "\n",
    "###\n",
    "# Load events\n",
    "#def get_prepared_data(root_file, silent=True):\n",
    "def get_prepared_data(root_file, silent=True):\n",
    "    \"\"\"\n",
    "    :root_file: from the config, 'in_{}_file' (come up with a better var name)\n",
    "    :silent:    prints out intermediate info if False\n",
    "    \"\"\"\n",
    "\n",
    "    if not silent: print('\\n\\nPreparing data for {}\\n'.format(root_file))\n",
    "    root_file = 'in_{}_file'.format(root_file)\n",
    "\n",
    "    inFileName = config[root_file]['name']\n",
    "    inFile = ur.open(inFileName)\n",
    "    if not silent: print(inFile.classnames())\n",
    "\n",
    "    tree = inFile[config[root_file]['tree']]\n",
    "    if not silent: print('Tree keys: \\n', tree.keys())\n",
    "    if not silent: print(type(tree))\n",
    "    tree.show()\n",
    "\n",
    "    dfall = tree.arrays(library='pd')\n",
    "\n",
    "    # shuffle the events\n",
    "    dfall = dfall.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "    ###\n",
    "    # Examine pandas dataset\n",
    "\n",
    "    # dump list of features\n",
    "    #dfall.columns\n",
    "\n",
    "    # examine first few events\n",
    "    dfall.head()\n",
    "\n",
    "    # take a look at feature distribution\n",
    "   # if not silent: print(dfall.describe())\n",
    "\n",
    "    label_weights = ( (dfall.loc[dfall[config[root_file]['target']]!=4])[config[root_file]['weights']].sum(), \\\n",
    "                      (dfall.loc[dfall[config[root_file]['target']]==4])[config[root_file]['weights']].sum() )\n",
    "    if not silent: print('\\ntotal label weights {}'.format(label_weights))\n",
    "\n",
    "    label_nevents = ( dfall.loc[dfall[config[root_file]['target']]!=4].shape[0], \\\n",
    "                      dfall.loc[dfall[config[root_file]['target']]==4].shape[0] )\n",
    "    if not silent: print ('total class number of events {}'.format(label_nevents))\n",
    "\n",
    "    ###\n",
    "    # Data preparation\n",
    "\n",
    "    if not silent: print ('Full data shape: {}'.format(dfall.shape))\n",
    "\n",
    "    # keep events with not negative weights\n",
    "    # it is not correct in principle, but\n",
    "    # many data science tools break given a negative weight\n",
    "    fulldata = dfall[dfall[config[root_file]['weights']]>=0]\n",
    "    if not silent: print ('Data with non-negative weights shape: {}'.format(fulldata.shape))\n",
    "\n",
    "    # weights and topHOF are not discriminative variables\n",
    "    # therefore, hide them in in separate vectors\n",
    "    # do not cut or shuffle after that!\n",
    "    target = fulldata[config[root_file]['target']]\n",
    "    del fulldata[config[root_file]['target']]\n",
    "    weights = fulldata[config[root_file]['weights']]\n",
    "    del fulldata[config[root_file]['weights']]\n",
    "    if not silent: print('\\nSeparated \"target\" and \"weight\" from \"fulldata\".\\n')\n",
    "\n",
    "    # tf doesn't tolerate targets other than 0/1\n",
    "    # replace topHOF==4 and !=4 as 0 and 1 respectively\n",
    "    # simple 'if target[i] == 4 : target[i] = 0' doesn't work on lxplus environment\n",
    "    targets = []\n",
    "    sig_vals = []\n",
    "    bkg_vals = []\n",
    "\n",
    "    if isinstance(config[root_file]['sig_val'], list) and isinstance(config[root_file]['bkg_val'], list) :\n",
    "        targets = config[root_file]['sig_val'] + config[root_file]['bkg_val']\n",
    "        sig_vals = config[root_file]['sig_val']\n",
    "        bkg_vals = config[root_file]['bkg_val']\n",
    "    else :\n",
    "        targets = [-99, 0, 1, 4]\n",
    "        sig_vals = [-99, 0, 1]\n",
    "        bkg_vals = [4]\n",
    "\n",
    "    if (config[root_file]['sig_val'] != None) ^ (config[root_file]['sig_val'] != None) :\n",
    "        print('WARNING: Config Sig/Bkg targets declaration issue: one is None other is not.')\n",
    "        print('WARNING: Using the default list [-99, 0, 1, 4]')\n",
    "\n",
    "    for val in targets:\n",
    "        if val in bkg_vals: target = target.replace(to_replace = val, value = 0)\n",
    "        else : target = target.replace(to_replace = val, value = 1)\n",
    "    # check that it worked\n",
    "    for i, v in target.items():\n",
    "        if not silent: print('Index: {}, value: {}'.format(i, v))\n",
    "        if i>20: break\n",
    "    if not silent: print('\\nReplaced topHOF values with 0 and 1.\\n')\n",
    "\n",
    "    ###\n",
    "    # Features selection/engineering\n",
    "\n",
    "    # define a pandas series object with only features\n",
    "    data = pd.DataFrame(fulldata, columns=config[root_file]['features'])\n",
    "    if not silent: print('Shape: {}'.format(data.shape))\n",
    "    #if not silent: print(data.describe())\n",
    "\n",
    "    # draw features plots\n",
    "    if root_file=='nominal':\n",
    "        plt.figure('Discriminative variables')\n",
    "        ax = data[target==0].hist(weights=weights[target==0], figsize=(15,12), color='b', alpha=0.5, density=True)\n",
    "        ax = ax.flatten()[:data.shape[1]]\n",
    "        data[target==1].hist(weights=weights[target==1], figsize=(15,12), color='r', alpha=0.5, density=True, ax=ax)\n",
    "        plt.savefig(plot_dir + 'discr_vars_plot_test.pdf')\n",
    "        plt.close()\n",
    "        if not silent: print('\\nCreated discriminative variables plots.\\n')\n",
    "\n",
    "\n",
    "    ###\n",
    "    # Transform the features\n",
    "\n",
    "\n",
    "    train_size = config['train_size']\n",
    "    #if not silent: print(data.describe())\n",
    "    X_train, X_test, y_train, y_test, weights_train, weights_test = \\\n",
    "        train_test_split(data, target, weights, train_size=train_size)\n",
    "\n",
    "    y_train, y_test, weights_train, weights_test = \\\n",
    "        y_train.reset_index(drop=True),y_test.reset_index(drop=True), \\\n",
    "        weights_train.reset_index(drop=True), weights_test.reset_index(drop=True)\n",
    "    if not silent: print ('\\nXtrain Shape: {}'.format(X_train.shape))\n",
    "    if not silent: print ('ytrain Shape: {}'.format(y_train.shape))\n",
    "    if not silent: print ('Training Weights: {}'.format(weights_train.shape, '\\n'))\n",
    "    if not silent: print ('Xtest Shape: {}'.format(X_test.shape))\n",
    "    if not silent: print ('ytest Shape: {}'.format(y_test.shape))\n",
    "    if not silent: print ('Test Weights: {}\\n'.format(weights_test.shape))\n",
    "\n",
    "    # extra split: test and validation\n",
    "    X_test, X_val, y_test, y_val, weights_test, weights_val, = \\\n",
    "        train_test_split(X_test, y_test, weights_test, train_size=1-config['validation_size'], shuffle=False)\n",
    "\n",
    "    ###\n",
    "    # Standardize the Data\n",
    "\n",
    "    # scale to mean of 0 and variance of 1.0: (x - mu)/sigma\n",
    "    scaler = StandardScaler()\n",
    "    X_train = scaler.fit_transform(X_train)\n",
    "    X_val = scaler.transform(X_val)\n",
    "    X_test = scaler.transform(X_test) # applies the transformation calculated the line above\n",
    "    ###\n",
    "    # Adjust the Test and Train sig/bkg weights\n",
    "\n",
    "#    class_weights_train = (weights_train[y_train==1].sum(), weights_train[y_train==0].sum())\n",
    "#    if not silent: print ('Class_weights_train: {}'.format(class_weights_train))\n",
    "#    for i in range(len(class_weights_train)):\n",
    "#        weights_train[y_train==i] *= max(class_weights_train)/class_weights_train[i] #equalize number of background and signal event\n",
    "#        weights_test[y_test==i] *= 1/(1-train_size) #increase test weight to compensate for sampling\n",
    "#\n",
    "#    if not silent: print ('\\nTrain : total weight sig {}'.format(weights_train[y_train == 1].sum()))\n",
    "#    if not silent: print ('Train : total weight bkg {}'.format(weights_train[y_train == 0].sum()))\n",
    "#    if not silent: print ('Test : total weight sig {} '.format(weights_test[y_test == 1].sum()))\n",
    "#    if not silent: print ('Test : total weight bkg {}\\n'.format(weights_test[y_test == 0].sum()))\n",
    "#\n",
    "#    # quickly take a look at weights\n",
    "#    if not silent: print(class_weights_train)\n",
    "#    if not silent: print(weights_train)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "14ac6409",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "met_pt               | float                    | AsDtype('>f4')\n",
      "bjet_E               | float                    | AsDtype('>f4')\n",
      "el_E                 | float                    | AsDtype('>f4')\n",
      "mu_E                 | float                    | AsDtype('>f4')\n",
      "bjet_pt              | float                    | AsDtype('>f4')\n",
      "el_pt                | float                    | AsDtype('>f4')\n",
      "mu_pt                | float                    | AsDtype('>f4')\n",
      "bjet_eta             | float                    | AsDtype('>f4')\n",
      "el_eta               | float                    | AsDtype('>f4')\n",
      "mu_eta               | float                    | AsDtype('>f4')\n",
      "bjet_phi             | float                    | AsDtype('>f4')\n",
      "el_phi               | float                    | AsDtype('>f4')\n",
      "mu_phi               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "dR_lep_close         | float                    | AsDtype('>f4')\n",
      "dR_lep_far           | float                    | AsDtype('>f4')\n",
      "mass_lep_close       | float                    | AsDtype('>f4')\n",
      "mass_lep_far         | float                    | AsDtype('>f4')\n",
      "dR_bjet_close        | float                    | AsDtype('>f4')\n",
      "dR_bjet_far          | float                    | AsDtype('>f4')\n",
      "dR_lep_el            | float                    | AsDtype('>f4')\n",
      "dR_lep_mu            | float                    | AsDtype('>f4')\n",
      "mass_lep_el          | float                    | AsDtype('>f4')\n",
      "mass_lep_mu          | float                    | AsDtype('>f4')\n",
      "dR_lep_1pt           | float                    | AsDtype('>f4')\n",
      "dR_lep_2pt           | float                    | AsDtype('>f4')\n",
      "mass_lep_1pt         | float                    | AsDtype('>f4')\n",
      "mass_lep_2pt         | float                    | AsDtype('>f4')\n",
      "mass_bjet_large      | float                    | AsDtype('>f4')\n",
      "mass_bjet_small      | float                    | AsDtype('>f4')\n",
      "dR_unb_close         | float                    | AsDtype('>f4')\n",
      "dR_unb_far           | float                    | AsDtype('>f4')\n",
      "total_event_weight   | float                    | AsDtype('>f4')\n",
      "jet_GBHInit_topHa... | uint64_t                 | AsDtype('>u8')\n",
      "Event_number         | uint64_t                 | AsDtype('>u8')\n",
      "bjet_number          | uint64_t                 | AsDtype('>u8')\n"
     ]
    }
   ],
   "source": [
    "###\n",
    "# Prepare training data for DANN\n",
    "# label classifier: (source) nominal sample b-jets and (target) their labels\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = get_prepared_data('nominal')\n",
    "#X_train, X_val, X_test, y_train, y_val, y_test = get_prepared_data(\"3j3b.root\")\n",
    "y_train = pd.Series.to_numpy(y_train)\n",
    "y_val = pd.Series.to_numpy(y_val)\n",
    "y_test = pd.Series.to_numpy(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b3de106",
   "metadata": {
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "met_pt               | float                    | AsDtype('>f4')\n",
      "bjet_E               | float                    | AsDtype('>f4')\n",
      "el_E                 | float                    | AsDtype('>f4')\n",
      "mu_E                 | float                    | AsDtype('>f4')\n",
      "bjet_pt              | float                    | AsDtype('>f4')\n",
      "el_pt                | float                    | AsDtype('>f4')\n",
      "mu_pt                | float                    | AsDtype('>f4')\n",
      "bjet_eta             | float                    | AsDtype('>f4')\n",
      "el_eta               | float                    | AsDtype('>f4')\n",
      "mu_eta               | float                    | AsDtype('>f4')\n",
      "bjet_phi             | float                    | AsDtype('>f4')\n",
      "el_phi               | float                    | AsDtype('>f4')\n",
      "mu_phi               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "dR_lep_close         | float                    | AsDtype('>f4')\n",
      "dR_lep_far           | float                    | AsDtype('>f4')\n",
      "mass_lep_close       | float                    | AsDtype('>f4')\n",
      "mass_lep_far         | float                    | AsDtype('>f4')\n",
      "dR_bjet_close        | float                    | AsDtype('>f4')\n",
      "dR_bjet_far          | float                    | AsDtype('>f4')\n",
      "dR_lep_el            | float                    | AsDtype('>f4')\n",
      "dR_lep_mu            | float                    | AsDtype('>f4')\n",
      "mass_lep_el          | float                    | AsDtype('>f4')\n",
      "mass_lep_mu          | float                    | AsDtype('>f4')\n",
      "dR_lep_1pt           | float                    | AsDtype('>f4')\n",
      "dR_lep_2pt           | float                    | AsDtype('>f4')\n",
      "mass_lep_1pt         | float                    | AsDtype('>f4')\n",
      "mass_lep_2pt         | float                    | AsDtype('>f4')\n",
      "mass_bjet_large      | float                    | AsDtype('>f4')\n",
      "mass_bjet_small      | float                    | AsDtype('>f4')\n",
      "dR_unb_close         | float                    | AsDtype('>f4')\n",
      "dR_unb_far           | float                    | AsDtype('>f4')\n",
      "total_event_weight   | float                    | AsDtype('>f4')\n",
      "jet_GBHInit_topHa... | uint64_t                 | AsDtype('>u8')\n",
      "Event_number         | uint64_t                 | AsDtype('>u8')\n",
      "bjet_number          | uint64_t                 | AsDtype('>u8')\n",
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "met_pt               | float                    | AsDtype('>f4')\n",
      "bjet_E               | float                    | AsDtype('>f4')\n",
      "el_E                 | float                    | AsDtype('>f4')\n",
      "mu_E                 | float                    | AsDtype('>f4')\n",
      "bjet_pt              | float                    | AsDtype('>f4')\n",
      "el_pt                | float                    | AsDtype('>f4')\n",
      "mu_pt                | float                    | AsDtype('>f4')\n",
      "bjet_eta             | float                    | AsDtype('>f4')\n",
      "el_eta               | float                    | AsDtype('>f4')\n",
      "mu_eta               | float                    | AsDtype('>f4')\n",
      "bjet_phi             | float                    | AsDtype('>f4')\n",
      "el_phi               | float                    | AsDtype('>f4')\n",
      "mu_phi               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "dR_lep_close         | float                    | AsDtype('>f4')\n",
      "dR_lep_far           | float                    | AsDtype('>f4')\n",
      "mass_lep_close       | float                    | AsDtype('>f4')\n",
      "mass_lep_far         | float                    | AsDtype('>f4')\n",
      "dR_bjet_close        | float                    | AsDtype('>f4')\n",
      "dR_bjet_far          | float                    | AsDtype('>f4')\n",
      "dR_lep_el            | float                    | AsDtype('>f4')\n",
      "dR_lep_mu            | float                    | AsDtype('>f4')\n",
      "mass_lep_el          | float                    | AsDtype('>f4')\n",
      "mass_lep_mu          | float                    | AsDtype('>f4')\n",
      "dR_lep_1pt           | float                    | AsDtype('>f4')\n",
      "dR_lep_2pt           | float                    | AsDtype('>f4')\n",
      "mass_lep_1pt         | float                    | AsDtype('>f4')\n",
      "mass_lep_2pt         | float                    | AsDtype('>f4')\n",
      "mass_bjet_large      | float                    | AsDtype('>f4')\n",
      "mass_bjet_small      | float                    | AsDtype('>f4')\n",
      "dR_unb_close         | float                    | AsDtype('>f4')\n",
      "dR_unb_far           | float                    | AsDtype('>f4')\n",
      "total_event_weight   | float                    | AsDtype('>f4')\n",
      "jet_GBHInit_topHa... | uint64_t                 | AsDtype('>u8')\n",
      "Event_number         | uint64_t                 | AsDtype('>u8')\n",
      "bjet_number          | uint64_t                 | AsDtype('>u8')\n",
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "met_pt               | float                    | AsDtype('>f4')\n",
      "bjet_E               | float                    | AsDtype('>f4')\n",
      "el_E                 | float                    | AsDtype('>f4')\n",
      "mu_E                 | float                    | AsDtype('>f4')\n",
      "bjet_pt              | float                    | AsDtype('>f4')\n",
      "el_pt                | float                    | AsDtype('>f4')\n",
      "mu_pt                | float                    | AsDtype('>f4')\n",
      "bjet_eta             | float                    | AsDtype('>f4')\n",
      "el_eta               | float                    | AsDtype('>f4')\n",
      "mu_eta               | float                    | AsDtype('>f4')\n",
      "bjet_phi             | float                    | AsDtype('>f4')\n",
      "el_phi               | float                    | AsDtype('>f4')\n",
      "mu_phi               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "dR_lep_close         | float                    | AsDtype('>f4')\n",
      "dR_lep_far           | float                    | AsDtype('>f4')\n",
      "mass_lep_close       | float                    | AsDtype('>f4')\n",
      "mass_lep_far         | float                    | AsDtype('>f4')\n",
      "dR_bjet_close        | float                    | AsDtype('>f4')\n",
      "dR_bjet_far          | float                    | AsDtype('>f4')\n",
      "dR_lep_el            | float                    | AsDtype('>f4')\n",
      "dR_lep_mu            | float                    | AsDtype('>f4')\n",
      "mass_lep_el          | float                    | AsDtype('>f4')\n",
      "mass_lep_mu          | float                    | AsDtype('>f4')\n",
      "dR_lep_1pt           | float                    | AsDtype('>f4')\n",
      "dR_lep_2pt           | float                    | AsDtype('>f4')\n",
      "mass_lep_1pt         | float                    | AsDtype('>f4')\n",
      "mass_lep_2pt         | float                    | AsDtype('>f4')\n",
      "mass_bjet_large      | float                    | AsDtype('>f4')\n",
      "mass_bjet_small      | float                    | AsDtype('>f4')\n",
      "dR_unb_close         | float                    | AsDtype('>f4')\n",
      "dR_unb_far           | float                    | AsDtype('>f4')\n",
      "total_event_weight   | float                    | AsDtype('>f4')\n",
      "jet_GBHInit_topHa... | uint64_t                 | AsDtype('>u8')\n",
      "Event_number         | uint64_t                 | AsDtype('>u8')\n",
      "bjet_number          | uint64_t                 | AsDtype('>u8')\n"
     ]
    }
   ],
   "source": [
    "# domain classifier: (source) nominal and domain samples b-jets and (target) their domain labels\n",
    "Xdn_train, Xdn_val, Xdn_test, ydn_train, ydn_val, ydn_test = get_prepared_data('nominal_for_domain')\n",
    "Xd1_train, Xd1_val, Xd1_test, yd1_train, yd1_val, yd1_test = get_prepared_data('domain1')\n",
    "Xd2_train, Xd2_val, Xd2_test, yd2_train, yd2_val, yd2_test = get_prepared_data('domain2')\n",
    "#Xd1_train, Xd1_val, Xd1_test, yd1_train, yd1_val, yd1_test = get_prepared_data(\"3j3b_sherpa.root\")\n",
    "#Xd2_train, Xd2_val, Xd2_test, yd2_train, yd2_val, yd2_test = get_prepared_data(\"3j3b_sherpa_set3.root\")\n",
    "\n",
    "# training dataset\n",
    "nominal_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "nominal_dataset = nominal_dataset.batch(int(batch_size/2))\n",
    "domain1_dataset = tf.data.Dataset.from_tensor_slices((Xd1_train, yd1_train))\n",
    "domain1_dataset = domain1_dataset.batch(int(batch_size/2))\n",
    "training_dataset = tf.data.Dataset.zip((nominal_dataset, domain1_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6408ef83",
   "metadata": {
    "code_folding": [
     49,
     152,
     174
    ]
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "in user code:\n\n\n    TypeError: tf___prepare_data_for_dann_training() got multiple values for argument 'main_head_name'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 42>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     37\u001b[0m domain1_preds_head_name \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdomain1_preds\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     38\u001b[0m prepare_for_dann_training_fn \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(_prepare_data_for_dann_training,\n\u001b[0;32m     39\u001b[0m                                                  main_head_name\u001b[38;5;241m=\u001b[39mlabel_preds_head_name,\n\u001b[0;32m     40\u001b[0m                                                  domain1_head_name\u001b[38;5;241m=\u001b[39mdomain1_preds_head_name)\n\u001b[1;32m---> 42\u001b[0m training_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_dataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprepare_for_dann_training_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(training_dataset)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;66;03m# testing dataset\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:2050\u001b[0m, in \u001b[0;36mDatasetV2.map\u001b[1;34m(self, map_func, num_parallel_calls, deterministic, name)\u001b[0m\n\u001b[0;32m   2048\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m MapDataset(\u001b[38;5;28mself\u001b[39m, map_func, preserve_cardinality\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, name\u001b[38;5;241m=\u001b[39mname)\n\u001b[0;32m   2049\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2050\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallelMapDataset\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2051\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2052\u001b[0m \u001b[43m      \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2053\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_parallel_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2054\u001b[0m \u001b[43m      \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2055\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpreserve_cardinality\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   2056\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\data\\ops\\dataset_ops.py:5284\u001b[0m, in \u001b[0;36mParallelMapDataset.__init__\u001b[1;34m(self, input_dataset, map_func, num_parallel_calls, deterministic, use_inter_op_parallelism, preserve_cardinality, use_legacy_function, name)\u001b[0m\n\u001b[0;32m   5282\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_dataset \u001b[38;5;241m=\u001b[39m input_dataset\n\u001b[0;32m   5283\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_inter_op_parallelism \u001b[38;5;241m=\u001b[39m use_inter_op_parallelism\n\u001b[1;32m-> 5284\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_map_func \u001b[38;5;241m=\u001b[39m \u001b[43mstructured_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStructuredFunctionWrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5285\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmap_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5286\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transformation_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5287\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5288\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_legacy_function\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_legacy_function\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5289\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   5290\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_deterministic \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdefault\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:271\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__\u001b[1;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[0;32m    264\u001b[0m       warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    265\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEven though the `tf.config.experimental_run_functions_eagerly` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    266\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moption is set, this option does not apply to tf.data functions. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    267\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTo force eager execution of tf.data functions, please use \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    268\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`tf.data.experimental.enable_debug_mode()`.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    269\u001b[0m     fn_factory \u001b[38;5;241m=\u001b[39m trace_tf_function(defun_kwargs)\n\u001b[1;32m--> 271\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function \u001b[38;5;241m=\u001b[39m \u001b[43mfn_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    272\u001b[0m \u001b[38;5;66;03m# There is no graph to add in eager mode.\u001b[39;00m\n\u001b[0;32m    273\u001b[0m add_to_graph \u001b[38;5;241m&\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m context\u001b[38;5;241m.\u001b[39mexecuting_eagerly()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2567\u001b[0m, in \u001b[0;36mFunction.get_concrete_function\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2558\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_concrete_function\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   2559\u001b[0m   \u001b[38;5;124;03m\"\"\"Returns a `ConcreteFunction` specialized to inputs and execution context.\u001b[39;00m\n\u001b[0;32m   2560\u001b[0m \n\u001b[0;32m   2561\u001b[0m \u001b[38;5;124;03m  Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2565\u001b[0m \u001b[38;5;124;03m       or `tf.Tensor` or `tf.TensorSpec`.\u001b[39;00m\n\u001b[0;32m   2566\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2567\u001b[0m   graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_concrete_function_garbage_collected(\n\u001b[0;32m   2568\u001b[0m       \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   2569\u001b[0m   graph_function\u001b[38;5;241m.\u001b[39m_garbage_collector\u001b[38;5;241m.\u001b[39mrelease()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m   2570\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2533\u001b[0m, in \u001b[0;36mFunction._get_concrete_function_garbage_collected\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2531\u001b[0m   args, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   2532\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m-> 2533\u001b[0m   graph_function, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_define_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2534\u001b[0m   seen_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n\u001b[0;32m   2535\u001b[0m   captured \u001b[38;5;241m=\u001b[39m object_identity\u001b[38;5;241m.\u001b[39mObjectIdentitySet(\n\u001b[0;32m   2536\u001b[0m       graph_function\u001b[38;5;241m.\u001b[39mgraph\u001b[38;5;241m.\u001b[39minternal_captures)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2711\u001b[0m, in \u001b[0;36mFunction._maybe_define_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2708\u001b[0m   cache_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39mgeneralize(cache_key)\n\u001b[0;32m   2709\u001b[0m   (args, kwargs) \u001b[38;5;241m=\u001b[39m cache_key\u001b[38;5;241m.\u001b[39m_placeholder_value()  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[1;32m-> 2711\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_graph_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2712\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_cache\u001b[38;5;241m.\u001b[39madd(cache_key, cache_key_deletion_observer,\n\u001b[0;32m   2713\u001b[0m                          graph_function)\n\u001b[0;32m   2715\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function, filtered_flat_args\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2627\u001b[0m, in \u001b[0;36mFunction._create_graph_function\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   2622\u001b[0m missing_arg_names \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m   2623\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (arg, i) \u001b[38;5;28;01mfor\u001b[39;00m i, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(missing_arg_names)\n\u001b[0;32m   2624\u001b[0m ]\n\u001b[0;32m   2625\u001b[0m arg_names \u001b[38;5;241m=\u001b[39m base_arg_names \u001b[38;5;241m+\u001b[39m missing_arg_names\n\u001b[0;32m   2626\u001b[0m graph_function \u001b[38;5;241m=\u001b[39m ConcreteFunction(\n\u001b[1;32m-> 2627\u001b[0m     \u001b[43mfunc_graph_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc_graph_from_py_func\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2628\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2629\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_python_function\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2630\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2631\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2632\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput_signature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2633\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2634\u001b[0m \u001b[43m        \u001b[49m\u001b[43mautograph_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_autograph_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2635\u001b[0m \u001b[43m        \u001b[49m\u001b[43marg_names\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43marg_names\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2636\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapture_by_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_capture_by_value\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[0;32m   2637\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_function_attributes,\n\u001b[0;32m   2638\u001b[0m     spec\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_spec,\n\u001b[0;32m   2639\u001b[0m     \u001b[38;5;66;03m# Tell the ConcreteFunction to clean up its graph once it goes out of\u001b[39;00m\n\u001b[0;32m   2640\u001b[0m     \u001b[38;5;66;03m# scope. This is not the default behavior since it gets used in some\u001b[39;00m\n\u001b[0;32m   2641\u001b[0m     \u001b[38;5;66;03m# places (like Keras) where the FuncGraph lives longer than the\u001b[39;00m\n\u001b[0;32m   2642\u001b[0m     \u001b[38;5;66;03m# ConcreteFunction.\u001b[39;00m\n\u001b[0;32m   2643\u001b[0m     shared_func_graph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2644\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph_function\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py:1141\u001b[0m, in \u001b[0;36mfunc_graph_from_py_func\u001b[1;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, acd_record_initial_resource_uses)\u001b[0m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1139\u001b[0m   _, original_func \u001b[38;5;241m=\u001b[39m tf_decorator\u001b[38;5;241m.\u001b[39munwrap(python_func)\n\u001b[1;32m-> 1141\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m python_func(\u001b[38;5;241m*\u001b[39mfunc_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfunc_kwargs)\n\u001b[0;32m   1143\u001b[0m \u001b[38;5;66;03m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[39;00m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;66;03m# TensorArrays and `None`s.\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m func_outputs \u001b[38;5;241m=\u001b[39m nest\u001b[38;5;241m.\u001b[39mmap_structure(\n\u001b[0;32m   1146\u001b[0m     convert, func_outputs, expand_composites\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:248\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.trace_tf_function.<locals>.wrapped_fn\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;129m@eager_function\u001b[39m\u001b[38;5;241m.\u001b[39mdefun_with_attributes(\n\u001b[0;32m    243\u001b[0m     input_signature\u001b[38;5;241m=\u001b[39mstructure\u001b[38;5;241m.\u001b[39mget_flat_tensor_specs(\n\u001b[0;32m    244\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_structure),\n\u001b[0;32m    245\u001b[0m     autograph\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    246\u001b[0m     attributes\u001b[38;5;241m=\u001b[39mdefun_kwargs)\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_fn\u001b[39m(\u001b[38;5;241m*\u001b[39margs):  \u001b[38;5;66;03m# pylint: disable=missing-docstring\u001b[39;00m\n\u001b[1;32m--> 248\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[43mwrapper_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    249\u001b[0m   ret \u001b[38;5;241m=\u001b[39m structure\u001b[38;5;241m.\u001b[39mto_tensor_list(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_structure, ret)\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m [ops\u001b[38;5;241m.\u001b[39mconvert_to_tensor(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m ret]\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\data\\ops\\structured_function.py:177\u001b[0m, in \u001b[0;36mStructuredFunctionWrapper.__init__.<locals>.wrapper_helper\u001b[1;34m(*args)\u001b[0m\n\u001b[0;32m    175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _should_unpack(nested_args):\n\u001b[0;32m    176\u001b[0m   nested_args \u001b[38;5;241m=\u001b[39m (nested_args,)\n\u001b[1;32m--> 177\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mautograph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtf_convert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mag_ctx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mnested_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _should_pack(ret):\n\u001b[0;32m    179\u001b[0m   ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(ret)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:692\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m--> 692\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mag_error_metadata\u001b[38;5;241m.\u001b[39mto_exception(e)\n\u001b[0;32m    693\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:689\u001b[0m, in \u001b[0;36mconvert.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    688\u001b[0m   \u001b[38;5;28;01mwith\u001b[39;00m conversion_ctx:\n\u001b[1;32m--> 689\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint:disable=broad-except\u001b[39;00m\n\u001b[0;32m    691\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mag_error_metadata\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:352\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    349\u001b[0m   new_args \u001b[38;5;241m=\u001b[39m f\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m+\u001b[39m args\n\u001b[0;32m    350\u001b[0m   logging\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m3\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mForwarding call of partial \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m with\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m, f, new_args,\n\u001b[0;32m    351\u001b[0m               new_kwargs)\n\u001b[1;32m--> 352\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconverted_call\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    353\u001b[0m \u001b[43m      \u001b[49m\u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnew_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnew_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m      \u001b[49m\u001b[43mcaller_fn_scope\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcaller_fn_scope\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inspect_utils\u001b[38;5;241m.\u001b[39misbuiltin(f):\n\u001b[0;32m    360\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28meval\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\autograph\\impl\\api.py:439\u001b[0m, in \u001b[0;36mconverted_call\u001b[1;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[0;32m    437\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    438\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 439\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    440\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    441\u001b[0m     result \u001b[38;5;241m=\u001b[39m converted_f(\u001b[38;5;241m*\u001b[39meffective_args)\n",
      "\u001b[1;31mTypeError\u001b[0m: in user code:\n\n\n    TypeError: tf___prepare_data_for_dann_training() got multiple values for argument 'main_head_name'\n"
     ]
    }
   ],
   "source": [
    "# 'images' - coordinates in the phase spase.\n",
    "def _prepare_data_for_dann_training(nominal_data, domain1_data,\n",
    "                                    main_head_name='main_preds', domain1_head_name='domain_preds'):\n",
    "\n",
    "    nominal_images, nominal_labels = nominal_data\n",
    "    domain1_images, domain1_labels = domain1_data\n",
    "\n",
    "    num_nominal = tf.shape(nominal_images)[0]\n",
    "    num_domain1 = tf.shape(domain1_images)[0]\n",
    "\n",
    "    batch_images = tf.concat((nominal_images, domain1_images), axis=0)\n",
    "    batch_labels = tf.concat((nominal_labels, domain1_labels), axis=0)\n",
    "\n",
    "    # not to penalize the model for its prediscions on the domain images,\n",
    "    # by assigning a weight = 0 to these elements of the batch:\n",
    "    nominal_weight_per_sample = tf.tile([1.], [num_nominal])\n",
    "    domain1_weight_per_sample = tf.tile([0.], [num_domain1])\n",
    "    batch_sample_weights = tf.concat((nominal_weight_per_sample, domain1_weight_per_sample), axis=0)\n",
    "\n",
    "    # domain classifiscation\n",
    "    # we prepared ydn_train and yd1_train to be as what we need here\n",
    "    # but it is simpler to reuse batch_sample_weights that passing extra argument to the function\n",
    "    domain1_labels = batch_sample_weights\n",
    "    domain1_sample_weights = tf.tile([1.], [num_nominal + num_domain1])\n",
    "\n",
    "    batch_domain1 = {main_head_name: batch_labels,\n",
    "                     domain1_head_name: domain1_labels}\n",
    "    batch_sample_weights = {main_head_name: batch_sample_weights,\n",
    "                            domain1_head_name: domain1_sample_weights}\n",
    "\n",
    "    return batch_images, batch_domain1, batch_sample_weights\n",
    "\n",
    "\n",
    "import functools\n",
    "\n",
    "label_preds_head_name = 'label_preds'\n",
    "domain1_preds_head_name = 'domain1_preds'\n",
    "prepare_for_dann_training_fn = functools.partial(_prepare_data_for_dann_training,\n",
    "                                                 main_head_name=label_preds_head_name,\n",
    "                                                 domain1_head_name=domain1_preds_head_name)\n",
    "\n",
    "training_dataset = training_dataset.map(prepare_for_dann_training_fn, num_parallel_calls=4)\n",
    "print(training_dataset)\n",
    "\n",
    "\n",
    "# testing dataset\n",
    "testing_dataset = tf.data.Dataset.from_tensor_slices((Xd1_test, yd1_test))\n",
    "testing_dataset = testing_dataset.batch(batch_size)\n",
    "\n",
    "def _prepare_data_for_dann_testing(domain1_images, domain1_labels,\n",
    "                                      main_head_name='main_preds', domain1_head_name='domain_preds'):\n",
    "    # the batch contains only validation/test images from the target domain. \n",
    "    # this time, we want to evaluate the main loss over these images, so we assign a normal loss\n",
    "    # weight = 1 to each samples.\n",
    "    num_samples = tf.shape(domain1_images)[0]\n",
    "\n",
    "    # want to evaluate over\n",
    "    loss_weights = tf.tile([1], [num_samples])\n",
    "\n",
    "    # to assure we have labels as zeroes\n",
    "    domain1_labels = tf.tile([0], [num_samples])\n",
    "\n",
    "    batch_targets = {main_head_name: domain1_labels,\n",
    "                     domain1_head_name: domain1_labels}\n",
    "    batch_sample_weights = {main_head_name: loss_weights,\n",
    "                            domain1_head_name: loss_weights}\n",
    "\n",
    "    return domain1_images, batch_targets, batch_sample_weights\n",
    "\n",
    "\n",
    "prepare_for_dann_testing_fn = functools.partial(_prepare_data_for_dann_testing,\n",
    "                                                main_head_name=label_preds_head_name,\n",
    "                                                domain1_head_name=domain1_preds_head_name)\n",
    "\n",
    "testing_dataset = testing_dataset.map(prepare_for_dann_testing_fn, num_parallel_calls=4)\n",
    "print(testing_dataset)\n",
    "\n",
    "\n",
    "###\n",
    "# Build the model\n",
    "\n",
    "# build feature extractor layers and the label prediction model\n",
    "num_classes = 1 # 1 - probability to be of the target (additional b-jet) class\n",
    "#inputs = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "#fe_hiddens = []\n",
    "#for i in range(len(config['model']['hidden_layers'])):\n",
    "#    layer_name = 'feature_exctractor_{}'.format(i)\n",
    "#    if i==0:\n",
    "#        hidden_i = tf.keras.layers.Dense(\n",
    "#                units      = config['model']['hidden_layers'][i], \n",
    "#                activation = config['model']['act_func'][i],\n",
    "#                name       = layer_name\n",
    "#                )(inputs)\n",
    "#    else:\n",
    "#        hidden_i = tf.keras.layers.Dense(\n",
    "#                units      = config['model']['hidden_layers'][i],\n",
    "#                activation = config['model']['act_func'][i],\n",
    "#                name       = layer_name\n",
    "#                )(fe_hiddens[i-1])\n",
    "#    fe_hiddens.append(hidden_i)\n",
    "#\n",
    "#label_preds_head_name = 'label_preds'\n",
    "#label_preds = tf.keras.layers.Dense(\n",
    "#        units      = num_classes,\n",
    "#        activation = \"sigmoid\",\n",
    "#        name       = label_preds_head_name\n",
    "#        )(fe_hiddens[-1])\n",
    "\n",
    "inputs        = tf.keras.layers.Input(shape=(X_train.shape[1],))\n",
    "hidden1       = tf.keras.layers.Dense(30, activation='relu')(inputs)\n",
    "hidden2       = tf.keras.layers.Dense(15, activation='relu')(hidden1)\n",
    "hidden3       = tf.keras.layers.Dense(7, activation='relu')(hidden2)\n",
    "label_preds   = tf.keras.layers.Dense(num_classes, activation='softmax', name=label_preds_head_name)(hidden3)\n",
    "\n",
    "label_prediction_model = tf.keras.models.Model(\n",
    "        inputs  = inputs,\n",
    "        outputs = label_preds,\n",
    "        name    = 'classification_model')\n",
    "label_prediction_model.summary()\n",
    "\n",
    "label_prediction_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "                               loss='binary_crossentropy',\n",
    "                               metrics=config['model']['metrics'])\n",
    "\n",
    "from keras_custom_callbacks import SimpleLogCallback\n",
    "metrics_to_print_nom = collections.OrderedDict([(\"source-loss\", \"loss\"),\n",
    "                                            #(\"target-loss\", \"val_loss\"),\n",
    "                                            (\"source-acc\", \"accuracy\"),\n",
    "                                            #(\"target-acc\", \"val_acc\")\n",
    "])\n",
    "\n",
    "callbacks_nom = [\n",
    "        SimpleLogCallback(metrics_to_print_nom, num_epochs=config['model']['epochs'], log_frequency=1)\n",
    "]\n",
    "\n",
    "y_train = np.asarray(y_train).astype('int32').reshape((-1,1))\n",
    "y_test = np.asarray(y_test).astype('int32').reshape((-1,1))\n",
    "\n",
    "#nom_fit = label_prediction_model.fit(x = X_train,\n",
    "#                                     y = y_train,\n",
    "#                                     epochs = config['model']['epochs'],\n",
    "#                                     validation_data = (X_test, y_test),\n",
    "#                                     callbacks = callbacks_nom)\n",
    "\n",
    "#d1_as_nom_fit = label_prediction_model.fit(x = Xd1_train,\n",
    " #                                          y = yd1_train,\n",
    " #                                          epochs = config['model']['epochs'],\n",
    " #                                          validation_data = (Xd1_test, yd1_test),\n",
    " #                                          callbacks = callbacks_nom)\n",
    "\n",
    "\n",
    "@tf.custom_gradient\n",
    "def reverse_gradient(x, hp_lambda):\n",
    "    \"\"\"\n",
    "    Flips the sign of the incoming gradient during backpropagation.\n",
    "    :param x:           Input tensor\n",
    "    :param hp_lambda:   Hyper parameter lambda (DANN parameter)\n",
    "    :return:            Input tensor with reverse gradient (+ function to compute this reversed gradient)\n",
    "    \"\"\"\n",
    "\n",
    "    # Feed-forward operation:\n",
    "    y = tf.identity(x)\n",
    "\n",
    "    # Back-propagation/gradient-computing operation:\n",
    "    def _flip_gradient(dy):\n",
    "        # Since the decorated function 'reverse_gradient()' actually has 2 inputs\n",
    "        # (counting 'hp_lambda'), we have to return the gradient for each -- but\n",
    "        # anyway, the derivative wrt 'hp_lambda' is null:\n",
    "        return tf.math.negative(dy) * hp_lambda, tf.constant(0.)\n",
    "\n",
    "    return y, _flip_gradient\n",
    "\n",
    "\n",
    "# wrap the reverse gradient as a Keras layer\n",
    "class GradientReversal (tf.keras.layers.Layer):\n",
    "    \"\"\"\n",
    "    Flip the sign of gradient during training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, hp_lambda, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.hp_lambda = hp_lambda\n",
    "\n",
    "    def call(self, inputs, training=None):\n",
    "        return reverse_gradient(inputs, self.hp_lambda)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super().get_config()\n",
    "        config['hp_lambda'] = self.hp_lambda\n",
    "        return config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "\n",
    "# create domain classification model\n",
    "hp_lambda = tf.Variable(1.0)\n",
    "num_domains = 1 # 2: 'source' vs. 'target' (maybe not what we need), 1: prob. to be more or less 'source'-like\n",
    "\n",
    "domain1_preds_head_name = 'domain1_preds'\n",
    "#domain1_preds = GradientReversal(hp_lambda)(fe_hiddens[-1])\n",
    "#domain1_preds = tf.keras.layers.Dense(\n",
    "#        units      = 10,\n",
    "#        activation = 'relu',\n",
    "#        name       = 'domain1_dense'\n",
    "#        )(domain1_preds)\n",
    "#domain1_preds = tf.keras.layers.Dense(\n",
    "#        units      = num_domains,\n",
    "#        activation = \"sigmoid\",\n",
    "#        name       = domain1_preds_head_name\n",
    "#        )(domain1_preds)\n",
    "#\n",
    "#domain_classification_model1 = tf.keras.models.Model(\n",
    "#        inputs  = inputs,\n",
    "#        outputs = domain1_preds,\n",
    "#        name    = 'domain_dlassification_model')\n",
    "##domain_classification_model1.summary()\n",
    "\n",
    "domain1_preds = GradientReversal(hp_lambda)(hidden3)\n",
    "domain1_preds = tf.keras.layers.Dense(12, activation='linear')(domain1_preds)\n",
    "domain1_preds = tf.keras.layers.Dense(5, activation='linear', name=\"do5\")(domain1_preds)\n",
    "domain1_preds = tf.keras.layers.Activation(\"elu\", name=\"do6\")(domain1_preds)\n",
    "domain1_preds = tf.keras.layers.Dropout(0.5)(domain1_preds)\n",
    "domain1_preds = tf.keras.layers.Dense(num_domains, activation='softmax', name=domain1_preds_head_name)(domain1_preds)\n",
    "domain_classification_model1 = tf.keras.models.Model(inputs=inputs, outputs=domain1_preds)\n",
    "\n",
    "\n",
    "# build a combined model\n",
    "combined_model = tf.keras.models.Model(inputs=inputs, outputs=[label_preds, domain1_preds])\n",
    "\n",
    "combined_model.compile(\n",
    "                       optimizer=tf.keras.optimizers.Adam(),\n",
    "                       loss={\n",
    "                           label_preds_head_name:   'binary_crossentropy',\n",
    "                           domain1_preds_head_name: 'binary_crossentropy'},\n",
    "                       loss_weights={\n",
    "                           label_preds_head_name:   1,\n",
    "                           domain1_preds_head_name: 1},\n",
    "                       metrics={ # weighted_metrics ?\n",
    "                           label_preds_head_name:   config['model']['metrics'],\n",
    "                           domain1_preds_head_name: config['model']['metrics']}\n",
    "                       )\n",
    "\n",
    "combined_model.summary()\n",
    "\n",
    "\n",
    "# define some metrics\n",
    "metrics_to_print = collections.OrderedDict([\n",
    "    ('lc-loss', label_preds_head_name + '_loss'),\n",
    "    ('d-loss', domain1_preds_head_name + '_loss'),\n",
    "    ('lc-acc', label_preds_head_name + '_accuracy'),\n",
    "    ('d-acc', domain1_preds_head_name + '_accuracy'),\n",
    "    #('target c-acc', 'val_' + label_preds_head_name + '_acc')\n",
    "])\n",
    "\n",
    "callbacks = [\n",
    "        SimpleLogCallback(metrics_to_print, num_epochs=config['model']['epochs'], log_frequency=1)\n",
    "]\n",
    "\n",
    "\n",
    "# fit and save the model\n",
    "starting_time = time.time()\n",
    "if config['model']['new_or_load'] == 'new' :\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience = 3)\n",
    "    lr_callback = tf.keras.callbacks.LearningRateScheduler(lr_time_based_decay, verbose = 1)\n",
    "\n",
    "    the_fit = combined_model.fit(training_dataset,\n",
    "                                 epochs = config['model']['epochs'],\n",
    "                                 validation_data = testing_dataset,\n",
    "                                 verbose = 0,\n",
    "                                 #callbacks = [lr_callback, early_stopping, callbacks])\n",
    "                                 callbacks = callbacks)\n",
    "    model.save(config['model']['name'] + datetime.now().strftime('%d_%m_%Y_%H%M'))\n",
    "\n",
    "# evaluate the model\n",
    "loss_n, acc_n = model.evaluate(X_test, y_test.values, weighted_metrics=None)\n",
    "print('Measured model accuracy on the nominal dataset: {}, loss: {}'.format(acc_n, loss_n))\n",
    "loss_d1, acc_d1 = model.evaluate(Xd1_test, yd1_test, weighted_metrics=None)\n",
    "print('Measured model accuracy on the dom1 dataset: {}, loss: {}'.format(acc_d1, loss_d1))\n",
    "\n",
    "\n",
    "training_time = time.time() - starting_time\n",
    "print('Training time:i {}'.format(training_time))\n",
    "\n",
    "exit()\n",
    "# draw relevant plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aba1baf8",
   "metadata": {
    "code_folding": [
     1
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "met_pt               | float                    | AsDtype('>f4')\n",
      "bjet_E               | float                    | AsDtype('>f4')\n",
      "el_E                 | float                    | AsDtype('>f4')\n",
      "mu_E                 | float                    | AsDtype('>f4')\n",
      "bjet_pt              | float                    | AsDtype('>f4')\n",
      "el_pt                | float                    | AsDtype('>f4')\n",
      "mu_pt                | float                    | AsDtype('>f4')\n",
      "bjet_eta             | float                    | AsDtype('>f4')\n",
      "el_eta               | float                    | AsDtype('>f4')\n",
      "mu_eta               | float                    | AsDtype('>f4')\n",
      "bjet_phi             | float                    | AsDtype('>f4')\n",
      "el_phi               | float                    | AsDtype('>f4')\n",
      "mu_phi               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "dR_lep_close         | float                    | AsDtype('>f4')\n",
      "dR_lep_far           | float                    | AsDtype('>f4')\n",
      "mass_lep_close       | float                    | AsDtype('>f4')\n",
      "mass_lep_far         | float                    | AsDtype('>f4')\n",
      "dR_bjet_close        | float                    | AsDtype('>f4')\n",
      "dR_bjet_far          | float                    | AsDtype('>f4')\n",
      "dR_lep_el            | float                    | AsDtype('>f4')\n",
      "dR_lep_mu            | float                    | AsDtype('>f4')\n",
      "mass_lep_el          | float                    | AsDtype('>f4')\n",
      "mass_lep_mu          | float                    | AsDtype('>f4')\n",
      "dR_lep_1pt           | float                    | AsDtype('>f4')\n",
      "dR_lep_2pt           | float                    | AsDtype('>f4')\n",
      "mass_lep_1pt         | float                    | AsDtype('>f4')\n",
      "mass_lep_2pt         | float                    | AsDtype('>f4')\n",
      "mass_bjet_large      | float                    | AsDtype('>f4')\n",
      "mass_bjet_small      | float                    | AsDtype('>f4')\n",
      "dR_unb_close         | float                    | AsDtype('>f4')\n",
      "dR_unb_far           | float                    | AsDtype('>f4')\n",
      "total_event_weight   | float                    | AsDtype('>f4')\n",
      "jet_GBHInit_topHa... | uint64_t                 | AsDtype('>u8')\n",
      "Event_number         | uint64_t                 | AsDtype('>u8')\n",
      "bjet_number          | uint64_t                 | AsDtype('>u8')\n",
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "met_pt               | float                    | AsDtype('>f4')\n",
      "bjet_E               | float                    | AsDtype('>f4')\n",
      "el_E                 | float                    | AsDtype('>f4')\n",
      "mu_E                 | float                    | AsDtype('>f4')\n",
      "bjet_pt              | float                    | AsDtype('>f4')\n",
      "el_pt                | float                    | AsDtype('>f4')\n",
      "mu_pt                | float                    | AsDtype('>f4')\n",
      "bjet_eta             | float                    | AsDtype('>f4')\n",
      "el_eta               | float                    | AsDtype('>f4')\n",
      "mu_eta               | float                    | AsDtype('>f4')\n",
      "bjet_phi             | float                    | AsDtype('>f4')\n",
      "el_phi               | float                    | AsDtype('>f4')\n",
      "mu_phi               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "dR_lep_close         | float                    | AsDtype('>f4')\n",
      "dR_lep_far           | float                    | AsDtype('>f4')\n",
      "mass_lep_close       | float                    | AsDtype('>f4')\n",
      "mass_lep_far         | float                    | AsDtype('>f4')\n",
      "dR_bjet_close        | float                    | AsDtype('>f4')\n",
      "dR_bjet_far          | float                    | AsDtype('>f4')\n",
      "dR_lep_el            | float                    | AsDtype('>f4')\n",
      "dR_lep_mu            | float                    | AsDtype('>f4')\n",
      "mass_lep_el          | float                    | AsDtype('>f4')\n",
      "mass_lep_mu          | float                    | AsDtype('>f4')\n",
      "dR_lep_1pt           | float                    | AsDtype('>f4')\n",
      "dR_lep_2pt           | float                    | AsDtype('>f4')\n",
      "mass_lep_1pt         | float                    | AsDtype('>f4')\n",
      "mass_lep_2pt         | float                    | AsDtype('>f4')\n",
      "mass_bjet_large      | float                    | AsDtype('>f4')\n",
      "mass_bjet_small      | float                    | AsDtype('>f4')\n",
      "dR_unb_close         | float                    | AsDtype('>f4')\n",
      "dR_unb_far           | float                    | AsDtype('>f4')\n",
      "total_event_weight   | float                    | AsDtype('>f4')\n",
      "jet_GBHInit_topHa... | uint64_t                 | AsDtype('>u8')\n",
      "Event_number         | uint64_t                 | AsDtype('>u8')\n",
      "bjet_number          | uint64_t                 | AsDtype('>u8')\n",
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "met_pt               | float                    | AsDtype('>f4')\n",
      "bjet_E               | float                    | AsDtype('>f4')\n",
      "el_E                 | float                    | AsDtype('>f4')\n",
      "mu_E                 | float                    | AsDtype('>f4')\n",
      "bjet_pt              | float                    | AsDtype('>f4')\n",
      "el_pt                | float                    | AsDtype('>f4')\n",
      "mu_pt                | float                    | AsDtype('>f4')\n",
      "bjet_eta             | float                    | AsDtype('>f4')\n",
      "el_eta               | float                    | AsDtype('>f4')\n",
      "mu_eta               | float                    | AsDtype('>f4')\n",
      "bjet_phi             | float                    | AsDtype('>f4')\n",
      "el_phi               | float                    | AsDtype('>f4')\n",
      "mu_phi               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "dR_lep_close         | float                    | AsDtype('>f4')\n",
      "dR_lep_far           | float                    | AsDtype('>f4')\n",
      "mass_lep_close       | float                    | AsDtype('>f4')\n",
      "mass_lep_far         | float                    | AsDtype('>f4')\n",
      "dR_bjet_close        | float                    | AsDtype('>f4')\n",
      "dR_bjet_far          | float                    | AsDtype('>f4')\n",
      "dR_lep_el            | float                    | AsDtype('>f4')\n",
      "dR_lep_mu            | float                    | AsDtype('>f4')\n",
      "mass_lep_el          | float                    | AsDtype('>f4')\n",
      "mass_lep_mu          | float                    | AsDtype('>f4')\n",
      "dR_lep_1pt           | float                    | AsDtype('>f4')\n",
      "dR_lep_2pt           | float                    | AsDtype('>f4')\n",
      "mass_lep_1pt         | float                    | AsDtype('>f4')\n",
      "mass_lep_2pt         | float                    | AsDtype('>f4')\n",
      "mass_bjet_large      | float                    | AsDtype('>f4')\n",
      "mass_bjet_small      | float                    | AsDtype('>f4')\n",
      "dR_unb_close         | float                    | AsDtype('>f4')\n",
      "dR_unb_far           | float                    | AsDtype('>f4')\n",
      "total_event_weight   | float                    | AsDtype('>f4')\n",
      "jet_GBHInit_topHa... | uint64_t                 | AsDtype('>u8')\n",
      "Event_number         | uint64_t                 | AsDtype('>u8')\n",
      "bjet_number          | uint64_t                 | AsDtype('>u8')\n",
      "name                 | typename                 | interpretation                \n",
      "---------------------+--------------------------+-------------------------------\n",
      "met_pt               | float                    | AsDtype('>f4')\n",
      "bjet_E               | float                    | AsDtype('>f4')\n",
      "el_E                 | float                    | AsDtype('>f4')\n",
      "mu_E                 | float                    | AsDtype('>f4')\n",
      "bjet_pt              | float                    | AsDtype('>f4')\n",
      "el_pt                | float                    | AsDtype('>f4')\n",
      "mu_pt                | float                    | AsDtype('>f4')\n",
      "bjet_eta             | float                    | AsDtype('>f4')\n",
      "el_eta               | float                    | AsDtype('>f4')\n",
      "mu_eta               | float                    | AsDtype('>f4')\n",
      "bjet_phi             | float                    | AsDtype('>f4')\n",
      "el_phi               | float                    | AsDtype('>f4')\n",
      "mu_phi               | float                    | AsDtype('>f4')\n",
      "met_phi              | float                    | AsDtype('>f4')\n",
      "dR_lep_close         | float                    | AsDtype('>f4')\n",
      "dR_lep_far           | float                    | AsDtype('>f4')\n",
      "mass_lep_close       | float                    | AsDtype('>f4')\n",
      "mass_lep_far         | float                    | AsDtype('>f4')\n",
      "dR_bjet_close        | float                    | AsDtype('>f4')\n",
      "dR_bjet_far          | float                    | AsDtype('>f4')\n",
      "dR_lep_el            | float                    | AsDtype('>f4')\n",
      "dR_lep_mu            | float                    | AsDtype('>f4')\n",
      "mass_lep_el          | float                    | AsDtype('>f4')\n",
      "mass_lep_mu          | float                    | AsDtype('>f4')\n",
      "dR_lep_1pt           | float                    | AsDtype('>f4')\n",
      "dR_lep_2pt           | float                    | AsDtype('>f4')\n",
      "mass_lep_1pt         | float                    | AsDtype('>f4')\n",
      "mass_lep_2pt         | float                    | AsDtype('>f4')\n",
      "mass_bjet_large      | float                    | AsDtype('>f4')\n",
      "mass_bjet_small      | float                    | AsDtype('>f4')\n",
      "dR_unb_close         | float                    | AsDtype('>f4')\n",
      "dR_unb_far           | float                    | AsDtype('>f4')\n",
      "total_event_weight   | float                    | AsDtype('>f4')\n",
      "jet_GBHInit_topHa... | uint64_t                 | AsDtype('>u8')\n",
      "Event_number         | uint64_t                 | AsDtype('>u8')\n",
      "bjet_number          | uint64_t                 | AsDtype('>u8')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<ParallelMapDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), {'label_preds': TensorSpec(shape=(None,), dtype=tf.uint64, name=None), 'domain1_preds': TensorSpec(shape=(None,), dtype=tf.float32, name=None)}, {'label_preds': TensorSpec(shape=(None,), dtype=tf.float32, name=None), 'domain1_preds': TensorSpec(shape=(None,), dtype=tf.float32, name=None)})>\n",
      "<ParallelMapDataset element_spec=(TensorSpec(shape=(None, 5), dtype=tf.float32, name=None), {'label_preds': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'domain1_preds': TensorSpec(shape=(None,), dtype=tf.int32, name=None)}, {'label_preds': TensorSpec(shape=(None,), dtype=tf.int32, name=None), 'domain1_preds': TensorSpec(shape=(None,), dtype=tf.int32, name=None)})>\n",
      "Model: \"classification_model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 5)]               0         \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 30)                180       \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 15)                465       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 112       \n",
      "                                                                 \n",
      " label_preds (Dense)         (None, 1)                 8         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 765\n",
      "Trainable params: 765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Training: \u001b[92mstart\u001b[0m.\n",
      "Epoch 1/25\n",
      "68850/68868 [============================>.] - ETA: 0s - loss: -58976.0078 - auc: 0.5000 - accuracy: 0.4147 - false_negatives: 0.0000e+00 - false_positives: 1282054.0000 - precision: 0.4181 - recall: 1.0000 - true_negatives: 0.0000e+00 - true_positives: 921146.0000Epoch  0/25: \u001b[1msource-loss\u001b[0m = \u001b[94m-58802.445\u001b[0m; \u001b[1msource-acc\u001b[0m = \u001b[94m0.415\u001b[0m\n",
      "68868/68868 [==============================] - 353s 5ms/step - loss: -58802.4453 - auc: 0.5000 - accuracy: 0.4147 - false_negatives: 0.0000e+00 - false_positives: 1282378.0000 - precision: 0.4181 - recall: 1.0000 - true_negatives: 0.0000e+00 - true_positives: 921398.0000 - val_loss: -291977.1875 - val_auc: 0.5000 - val_accuracy: 0.4147 - val_false_negatives: 0.0000e+00 - val_false_positives: 384800.0000 - val_precision: 0.4180 - val_recall: 1.0000 - val_true_negatives: 0.0000e+00 - val_true_positives: 276332.0000\n",
      "Epoch 2/25\n",
      "68856/68868 [============================>.] - ETA: 0s - loss: -1562167.6250 - auc: 0.5000 - accuracy: 0.4148 - false_negatives: 0.0000e+00 - false_positives: 1282134.0000 - precision: 0.4181 - recall: 1.0000 - true_negatives: 0.0000e+00 - true_positives: 921258.0000"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 162>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    159\u001b[0m y_train \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_train)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m    160\u001b[0m y_test \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(y_test)\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint32\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mreshape((\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m--> 162\u001b[0m nom_fit \u001b[38;5;241m=\u001b[39m \u001b[43mlabel_prediction_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    163\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    164\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mepochs\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    165\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    166\u001b[0m \u001b[43m                                     \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcallbacks_nom\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    168\u001b[0m d1_as_nom_fit \u001b[38;5;241m=\u001b[39m label_prediction_model\u001b[38;5;241m.\u001b[39mfit(x \u001b[38;5;241m=\u001b[39m Xd1_train,\n\u001b[0;32m    169\u001b[0m                                            y \u001b[38;5;241m=\u001b[39m yd1_train,\n\u001b[0;32m    170\u001b[0m                                            epochs \u001b[38;5;241m=\u001b[39m config[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    171\u001b[0m                                            validation_data \u001b[38;5;241m=\u001b[39m (Xd1_test, yd1_test),\n\u001b[0;32m    172\u001b[0m                                            callbacks \u001b[38;5;241m=\u001b[39m callbacks_nom)\n\u001b[0;32m    175\u001b[0m \u001b[38;5;129m@tf\u001b[39m\u001b[38;5;241m.\u001b[39mcustom_gradient\n\u001b[0;32m    176\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreverse_gradient\u001b[39m(x, hp_lambda):\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\keras\\engine\\training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1431\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1432\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[0;32m   1433\u001b[0m       x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[0;32m   1434\u001b[0m       y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1443\u001b[0m       model\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   1444\u001b[0m       steps_per_execution\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution)\n\u001b[1;32m-> 1445\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1446\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1447\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1448\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1449\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1450\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1451\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1452\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1454\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1456\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m   1457\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[0;32m   1458\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\keras\\utils\\traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 64\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     65\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:  \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m     66\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\keras\\engine\\training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[1;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[0;32m   1754\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m   1755\u001b[0m   callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[1;32m-> 1756\u001b[0m   tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtest_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1757\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[0;32m   1758\u001b[0m     context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    912\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    914\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 915\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    917\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    918\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 954\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stateful_fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    955\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[0;32m    956\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    957\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2450\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[0;32m   2451\u001b[0m   (graph_function,\n\u001b[0;32m   2452\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2453\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1856\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1857\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1859\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1860\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1861\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcancellation_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcancellation_manager\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   1862\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1863\u001b[0m     args,\n\u001b[0;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1865\u001b[0m     executing_eagerly)\n\u001b[0;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _InterpolateFunctionError(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    496\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m cancellation_manager \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 497\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    498\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msignature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    499\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_num_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    500\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    501\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    502\u001b[0m \u001b[43m        \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mctx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    503\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    504\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m    505\u001b[0m         \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msignature\u001b[38;5;241m.\u001b[39mname),\n\u001b[0;32m    506\u001b[0m         num_outputs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    509\u001b[0m         ctx\u001b[38;5;241m=\u001b[39mctx,\n\u001b[0;32m    510\u001b[0m         cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_manager)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\tensorflow-session\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if config['model']['new_or_load'] == 'new' :\n",
    "    print('Fit history content: {}\\n'.format(the_fit.history))\n",
    "\n",
    "    plt.figure('Training loss')\n",
    "    plt.plot(the_fit.history['loss'],     color='red',  alpha=0.5, label='training loss')\n",
    "    plt.plot(the_fit.history['val_loss'], color='blue', alpha=0.5, label='testing loss')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training loss')\n",
    "    plt.savefig(plot_dir + 'training_loss.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure('Learning rate')\n",
    "    plt.plot(the_fit.history['lr'], label='learning rate')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Learning rate')\n",
    "    plt.savefig(plot_dir + 'learning_rate.pdf')\n",
    "    plt.close()\n",
    "\n",
    "    plt.figure('Train and Val Loss and Acc')\n",
    "    plt.plot(the_fit.history['loss'],         label='train loss')\n",
    "    plt.plot(the_fit.history['val_loss'],     label='val loss')\n",
    "    plt.plot(the_fit.history['accuracy'],     label='train acc')\n",
    "    plt.plot(the_fit.history['val_accuracy'], label='val acc')\n",
    "    plt.legend(fontsize=12)\n",
    "    plt.title('Stats')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss/Accuracy')\n",
    "    plt.savefig(plot_dir + 'stats.pdf')\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "###\n",
    "# Use the model to make predictions\n",
    "\n",
    "y_pred_test = model.predict(X_test).ravel()\n",
    "y_pred_train = model.predict(X_train).ravel()\n",
    "\n",
    "# do the ROC curve\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "auc_test = roc_auc_score(y_true=y_test, y_score=y_pred_test, sample_weight=None) #, sample_weight=weights_test)\n",
    "print(\"\\t\\tauc_test done\")\n",
    "auc_train = roc_auc_score(y_true=y_train.values, y_score=y_pred_train, sample_weight=None) #,sample_weight=weights_train)\n",
    "print(\"\\t\\tauc_train done\")\n",
    "print('auc test:',auc_test)\n",
    "print ('auc train:',auc_train)\n",
    "\n",
    "fpr1,tpr1,_ = roc_curve(y_true=y_train, y_score=y_pred_train, sample_weight=None) #, sample_weight=weights_train)\n",
    "fpr2,tpr2,_ = roc_curve(y_true=y_test,  y_score=y_pred_test, sample_weight=None) #,  sample_weight=weights_test)\n",
    "plt.figure('ROC curve')\n",
    "label_train = 'train (AUC = ' + str(auc_train) + ')'\n",
    "label_test = 'test (AUC = ' + str(auc_test) + ')'\n",
    "plt.plot(fpr1, tpr1, color='blue', lw=2, label=label_train, alpha=0.5)\n",
    "plt.plot(fpr2, tpr2, color='red',  lw=2, label=label_test,  alpha=0.5)\n",
    "plt.legend(fontsize=12)\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.savefig(plot_dir + 'roc.pdf')\n",
    "plt.close()\n",
    "\n",
    "###\n",
    "# Significance function\n",
    "\n",
    "from math import sqrt\n",
    "from math import log\n",
    "def amsasimov(s,b):\n",
    "    if b<=0 or s<=0:\n",
    "        return 0\n",
    "    try:\n",
    "        return sqrt(2*((s+b)*log(1+float(s)/b)-s))\n",
    "    except ValueError:\n",
    "        print(1+float(s)/b)\n",
    "        print (2*((s+b)*log(1+float(s)/b)-s))\n",
    "\n",
    "int_pred_test_sig = [weights_test[(y_test ==1) & (y_pred_test > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "int_pred_test_bkg = [weights_test[(y_test ==0) & (y_pred_test > th_cut)].sum() for th_cut in np.linspace(0,1,num=50)]\n",
    "vamsasimov = [amsasimov(sumsig,sumbkg) for (sumsig,sumbkg) in zip(int_pred_test_sig,int_pred_test_bkg)]\n",
    "Z = max(vamsasimov)\n",
    "print('Z value: {}'.format(Z))\n",
    "\n",
    "plt.figure('Significance')\n",
    "plt.plot(np.linspace(0,1,num=50),vamsasimov, label='Significance (Z = {})'.format(np.round(Z,decimals=2)))\n",
    "\n",
    "plt.title('NN Significance')\n",
    "plt.xlabel('Threshold')\n",
    "plt.ylabel('Significance')\n",
    "plt.legend()\n",
    "plt.savefig(plot_dir + 'significance_xgb.pdf')\n",
    "plt.close()\n",
    "\n",
    "\n",
    "###\n",
    "# Plot Sig and Bkg nn scores spectra\n",
    "from plot_bkg_sig_nn_spectra import compare_train_test\n",
    "\n",
    "compare_train_test(y_pred_train, y_train, y_pred_test, y_test,\n",
    "                   xlabel='NN Score', title='NN',\n",
    "                   weights_train=weights_train.values, weights_test=weights_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa836e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
